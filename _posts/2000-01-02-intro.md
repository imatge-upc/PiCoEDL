---
title: "Abstract"
bg: blue
color: white
fa-icon: quote-left
---

*Defining a reward function in Reinforcement Learning (RL) is not always possible or very costly. For this reason, there is a great interest in training agents in a task-agnostic manner making use of intrinsic motivations and unsupervised techniques. Due to the complexity to learn useful behaviours in pixel-based domains, the results obtained in RL are still far from the remarkable results obtained in domains such as computer vision and natural language processing. We hypothesize that RL agents will also benefit from unsupervised pre-trainings with no extrinsic rewards, analogously to how humans mostly learn, especially in the early stages of life. Our main contribution is the deployment of the \textit{Explore, Discover and Learn} (EDL)~\cite{campos2020explore} paradigm for unsupervised learning to the pixel space. In particular, our work focuses on the MineRL environment, where the observation of the agent is represented by: (a) its spatial coordinates in the Minecraft virtual world, and (b) an image from an egocentric viewpoint.*

If you find this work useful, please consider citing:

<i>
Juan Jose Nieto, Roger Creus, and Xavier Giro-i-Nieto. "Discovery and Learning of Minecraft Navigation Goals\\from Pixels and Coordinates", 2021.
</i>

Find our extended abstract in [this PDF](../assets/PiCoEDL-Nieto-2021.pdf).


